{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下面是CEM的测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "task_depth = 6\n",
    "# 设定cell大小\n",
    "m, n = 5, 5\n",
    "cell_grid_map = np.random.randint(0,5,(m,n))\n",
    "print(cell_grid_map)\n",
    "index = np.argmax(cell_grid_map)\n",
    "x = int(index / n)\n",
    "y = index % n\n",
    "\n",
    "# 挖掘动作空间\n",
    "action_space_approach = [1,0,0]\n",
    "action_space_dig = [0,1,0]\n",
    "action_space_dump = [0,0,1]\n",
    "action_list_cem = []\n",
    "\n",
    "while cell_grid_map[x,y] > task_depth:\n",
    "    cell_grid_map[x,y] = task_depth\n",
    "    action_list_cem.append(action_space_approach)\n",
    "    action_list_cem.append(action_space_dig)\n",
    "    action_list_cem.append(action_space_dump)\n",
    "    index = np.argmax(cell_grid_map)\n",
    "    x = int(index / n)\n",
    "    y = index % n  \n",
    "print(cell_grid_map) \n",
    "print(action_list_cem)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 5, 5)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 设定cell大小\n",
    "m, n = 5, 5\n",
    "train_size = 10000\n",
    "# 最低深度\n",
    "min_depth = -5 \n",
    "# 最高深度\n",
    "max_depth = 10\n",
    "\n",
    "np_save = np.random.randint(min_depth, max_depth, (train_size,m,n))\n",
    "np.save(\"cell_x\",np_save)\n",
    "print(np_save.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65790\n",
      "[[ 4. -5. -4. -5.  2.]\n",
      " [-5. -5. -5.  1. -1.]\n",
      " [ 2.  4.  3. -5. -3.]\n",
      " [-5.  1. -5. -2. -5.]\n",
      " [-5.  2. -1.  3.  5.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "task_depth = -5\n",
    "np_save = np.load('cell_x.npy')\n",
    "\n",
    "cell_grid = np.ones([train_size*10 ,m,n])\n",
    "\n",
    "index = np.argmax(np_save[0])\n",
    "x = int(index / n)\n",
    "y = index % n\n",
    "\n",
    "# 挖掘输出坐标\n",
    "action_list_cem = []\n",
    "index_chop = 0\n",
    "for i in range(0,train_size):\n",
    "    while np_save[i,x,y] > task_depth:\n",
    "        cell_grid[index_chop] = np_save[i]\n",
    "        index_chop = index_chop + 1\n",
    "        action_list_cem.append(index)\n",
    "        np_save[i,x,y] = task_depth\n",
    "        index = np.argmax(np_save[i])\n",
    "        x = int(index / n)\n",
    "        y = index % n\n",
    "    if i == 3000:\n",
    "        break  \n",
    "print(len(action_list_cem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import torchvision      # 数据库模块\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(  # input shape (1, 32, 32)\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,      # input height\n",
    "                out_channels=16,    # n_filters\n",
    "                kernel_size=3,      # filter size\n",
    "                stride=1,           # filter movement/step\n",
    "                padding=1,      # 如果想要 con2d 出来的图片长宽没有变化, padding=(kernel_size-1)/2 当 stride=1\n",
    "            ),      # output shape (16, 28, 28)\n",
    "            nn.ReLU(),    # activation\n",
    "            nn.MaxPool2d(kernel_size=2),    # 在 2x2 空间里向下采样, output shape (16, 14, 14)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(  # input shape (16, 14, 14)\n",
    "            nn.Conv2d(16, 32, 3, 1, 1),  # output shape (32, 14, 14)\n",
    "            nn.ReLU(),  # activation\n",
    "            nn.MaxPool2d(kernel_size=2),  # output shape (32, 7, 7)\n",
    "        )\n",
    "        self.out1 = nn.Linear(32, 128)   # fully connected layer, output 10 classes\n",
    "        self.out = nn.Linear(128, 128)\n",
    "        self.test = nn.Linear(128,25)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(x.size(0), -1)   # 展平多维的卷积图成 (batch_size, 32 * 7 * 7)\n",
    "        #拼接步骤\n",
    "        \n",
    "        # print(x.shape)\n",
    "        # print(y.shape)\n",
    "        # x = torch.cat([x,y],1)\n",
    "\n",
    "        output = self.out1(x)\n",
    "        output = self.out(output)\n",
    "        output = self.test(output)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-24 16:20:38\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/duanchenxi/project/GitHub/hello-world/tasknet/cem_test.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/duanchenxi/project/GitHub/hello-world/tasknet/cem_test.ipynb#W3sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m         loss \u001b[39m=\u001b[39m loss_func(output, b_y[step:step\u001b[39m+\u001b[39mbacht_size])   \u001b[39m# cross entropy loss\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/duanchenxi/project/GitHub/hello-world/tasknet/cem_test.ipynb#W3sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m         optimizer\u001b[39m.\u001b[39mzero_grad()           \u001b[39m# clear gradients for this training step\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/duanchenxi/project/GitHub/hello-world/tasknet/cem_test.ipynb#W3sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m         loss\u001b[39m.\u001b[39;49mbackward()                 \u001b[39m# backpropagation, compute gradients\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/duanchenxi/project/GitHub/hello-world/tasknet/cem_test.ipynb#W3sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m         optimizer\u001b[39m.\u001b[39mstep()                \u001b[39m# apply gradients\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/duanchenxi/project/GitHub/hello-world/tasknet/cem_test.ipynb#W3sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m torch\u001b[39m.\u001b[39msave(cnn, \u001b[39m'\u001b[39m\u001b[39mcem_net.pkl\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py38/lib/python3.8/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py38/lib/python3.8/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "EPOCH = 1000\n",
    "LR = 0.001          # 学习率\n",
    "\n",
    "cnn = CNN()\n",
    "\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)   # optimize all cnn parameters\n",
    "loss_func = nn.CrossEntropyLoss()   # the target label is not one-hotted\n",
    "sample_size = len(action_list_cem)\n",
    "s_ = np.expand_dims(cell_grid[:sample_size], axis=1)\n",
    "torch_data = torch.Tensor(s_)\n",
    "\n",
    "# print(cnn(torch_data))\n",
    "\n",
    "b_y = torch.LongTensor(action_list_cem)\n",
    "print(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time())))\n",
    "bacht_size = 40\n",
    "for epoch in range(EPOCH):\n",
    "    for step in range(0,sample_size-1000,bacht_size):   # 分配 batch data, normalize x when iterate train_loader\n",
    "        output = cnn(torch_data[step:step+bacht_size])               # cnn output\n",
    "        loss = loss_func(output, b_y[step:step+bacht_size])   # cross entropy loss\n",
    "        optimizer.zero_grad()           # clear gradients for this training step\n",
    "        loss.backward()                 # backpropagation, compute gradients\n",
    "        optimizer.step()                # apply gradients\n",
    "\n",
    "torch.save(cnn, 'cem_net.pkl')\n",
    "print(time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(time.time())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_re = 60\n",
    "index_start = sample_size-1000\n",
    "test_output = cnn(torch_data[index_start:(index_start + index_re)])\n",
    "pred_y = torch.max(test_output, 1)[1].data.numpy().squeeze()\n",
    "print(pred_y, 'prediction number')\n",
    "print(b_y[index_start:(index_start + index_re)].numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "43103ebe49f20780c0555c255a4ff1c6773ce139c9c7300782dfd117b1d10422"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
